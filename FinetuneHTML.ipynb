{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcDif-GdzV3x"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoPl6i2O3H7m",
        "outputId": "ec5813e6-d4ec-470d-f538-cdde0e319e1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIE9gh9ibGl3",
        "outputId": "c3a488ea-e3d3-4934-b5de-28082e1e04e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vL-Bz8d843Gk"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"jawerty/html_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7aX3CfwyA6pJ"
      },
      "outputs": [],
      "source": [
        "data = dataset[\"train\"].train_test_split(test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oebRvbtUA8mJ",
        "outputId": "dcfac76f-84ac-4f72-af2f-da28eb14a410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['label', 'html'],\n",
              "        num_rows: 34\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['label', 'html'],\n",
              "        num_rows: 9\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ckifp7K_GFbd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer, AdamW\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "10q1Z15fC47u"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, examples):\n",
        "        self.examples = examples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.examples[idx]\n",
        "        return {\n",
        "            \"label\": example[\"label\"],\n",
        "            \"html\": example[\"html\"]\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "a5tXxUY8GlQD"
      },
      "outputs": [],
      "source": [
        "# Load your dataset\n",
        "# Replace the following line with loading your actual dataset\n",
        "train_examples = data['train']\n",
        "test_examples = data['test']\n",
        "# Create DataLoader for training and test sets\n",
        "train_dataset = MyDataset(train_examples)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "test_dataset = MyDataset(test_examples)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoiyT_8UGqeW",
        "outputId": "070530c0-48e6-44b4-cebe-14541b7a5d39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "# Define T5 model and tokenizer\n",
        "model_name = \"t5-small\"\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name, src_lang=\"en\", tgt_lang=\"html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POPy7ytGG2ux",
        "outputId": "65640af6-4be8-4d12-d7c3-b4e49b267a76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define optimizer and loss function\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AqoQ0R8qa-6g"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "rouge_scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLYdayUeG8zK",
        "outputId": "fc5c4f63-e58e-4e40-8d74-ba8c483357f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Train Loss: 7.473968452877468\n",
            "Epoch 2, Train Loss: 6.186974472469753\n",
            "Epoch 3, Train Loss: 5.838557667202419\n",
            "Epoch 4, Train Loss: 5.4702241155836315\n",
            "Epoch 5, Train Loss: 5.565755473242866\n",
            "Epoch 6, Train Loss: 5.063986778259277\n",
            "Epoch 7, Train Loss: 5.14213498433431\n",
            "Epoch 8, Train Loss: 5.00471215777927\n",
            "Epoch 9, Train Loss: 4.8204479747348365\n",
            "Epoch 10, Train Loss: 4.609102831946479\n",
            "Epoch 11, Train Loss: 4.606663015153673\n",
            "Epoch 12, Train Loss: 4.403062873416477\n",
            "Epoch 13, Train Loss: 4.455058309766981\n",
            "Epoch 14, Train Loss: 4.349659946229723\n",
            "Epoch 15, Train Loss: 4.363509045706855\n",
            "Epoch 16, Train Loss: 4.205103026496039\n",
            "Epoch 17, Train Loss: 4.230042086707221\n",
            "Epoch 18, Train Loss: 4.085311386320326\n",
            "Epoch 19, Train Loss: 4.127061261071099\n",
            "Epoch 20, Train Loss: 4.101379844877455\n",
            "Epoch 21, Train Loss: 4.055003219180637\n",
            "Epoch 22, Train Loss: 3.929269128375583\n",
            "Epoch 23, Train Loss: 3.94476490550571\n",
            "Epoch 24, Train Loss: 3.9423827860090466\n",
            "Epoch 25, Train Loss: 3.8225817150539823\n",
            "Epoch 26, Train Loss: 3.940748824013604\n",
            "Epoch 27, Train Loss: 3.8536614576975503\n",
            "Epoch 28, Train Loss: 3.7231258286370172\n",
            "Epoch 29, Train Loss: 3.8197340170542398\n",
            "Epoch 30, Train Loss: 3.789954768286811\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 30\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train_loss = 0.0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        # Tokenize input and output\n",
        "        input_texts = batch[\"label\"]\n",
        "        target_texts = batch[\"html\"]\n",
        "\n",
        "        inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        targets = tokenizer(target_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(**inputs, labels=targets[\"input_ids\"])\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv-zwS8FGTD4",
        "outputId": "7be4ef0f-8008-422b-bdda-296fa5c6a48d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average ROUGE Score: 0.11716462798486106\n"
          ]
        }
      ],
      "source": [
        "from rouge import Rouge\n",
        "model.eval()\n",
        "total_rouge_score = 0.0\n",
        "rouge_scorer = Rouge()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in test_dataloader:\n",
        "        input_texts = batch[\"label\"]\n",
        "        target_texts = batch[\"html\"]\n",
        "\n",
        "        # Join the lists into strings\n",
        "        input_texts = \" \".join([\" \".join(inputs) for inputs in input_texts])\n",
        "        target_texts = \" \".join([\" \".join(targets) for targets in target_texts])\n",
        "\n",
        "        inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        targets = tokenizer(target_texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        outputs = model.generate(**inputs)\n",
        "        generated_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # Assuming batch size 1\n",
        "\n",
        "        # Compute ROUGE score using the rouge library\n",
        "        rouge_scores = rouge_scorer.get_scores(generated_text, target_texts, avg=True)\n",
        "        total_rouge_score += rouge_scores[\"rouge-l\"][\"f\"]\n",
        "\n",
        "avg_rouge_score = total_rouge_score / len(test_dataloader)\n",
        "print(f\"Average ROUGE Score: {avg_rouge_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "DdN-VwYvGT6k"
      },
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model.save_pretrained(\"t5_fine_tuned\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
